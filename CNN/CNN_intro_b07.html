<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CNN_intro_b07</title>
    
    <!-- CSS 框架 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/water.css@2/out/dark.min.css">
    
    <!-- 代碼高亮 -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/base16/darcula.min.css">
    
    <!-- 自定義樣式 -->
    <style>
        
                body {
                    max-width: 900px;
                    margin: 0 auto;
                    padding: 20px;
                }
                /* 提升代碼塊對比度 */
                pre {
                    background: #1e1e1e !important;
                    border: 1px solid #3e3e3e;
                }
                pre code {
                    background: #1e1e1e !important;
                }
                code {
                    background: #2d2d2d !important;
                }
                /* 引用塊對比度 */
                blockquote {
                    background: #2d2d2d;
                    border-left: 4px solid #4a9eff;
                }
                    
        /* 通用代碼塊樣式 */
        pre code {
            display: block;
            padding: 1.5em;
            border-radius: 8px;
            overflow-x: auto;
            line-height: 1.6;
        }

        /* Mermaid 圖表樣式 */
        
        .mermaid {
            margin: 2em 0;
            padding: 1.5em;
            text-align: center;
            border-radius: 8px;
        }
        
        .mermaid {
            background: #2c3034;
            border: 1px solid #444;
        }
            
        
        /* 響應式調整 */
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            .container, .markdown-body, .latex-body, .window-body, .nes-container { # Added .nes-container here
                padding: 15px;
            }
            pre code {
                padding: 1em;
            }
        }
        
        
    </style>
</head>
<body>
    <div class="container"><!-- Path: General_python/CNN | Timestamp: 2025-10-07 13:31:00 | Version: b07 -->
<h1>從經典案例學習 CNN：手寫數字辨識完整實戰指南</h1>
<p>在學習完 CNN 的理論架構之後，最好的方式就是透過經典案例來理解理論如何在實際程式碼中實現。本文將以 <strong>MNIST 手寫數字辨識</strong> 與 <strong>CIFAR-10 彩色影像分類</strong> 作為範例，這兩個任務是學習 CNN 的最佳起點。</p>
<p><strong>本指南特色</strong>：<br />
- ✅ 所有程式碼經過 Colab 測試，可直接執行<br />
- ✅ 完整的 MNIST 與 CIFAR-10 資料集介紹<br />
- ✅ Keras 與 PyTorch 框架詳細比較<br />
- ✅ 從基礎到進階的完整學習路徑<br />
- ✅ 詳細的專有名詞與函數說明</p>
<hr />
<h2>學習路徑視覺化</h2>
<div class="mermaid">
graph TB
    Start([開始學習 CNN]) --&gt; Choice{有程式經驗?}

    Choice --&gt;|初學者| Week1[Week 1-2: 基礎知識]
    Choice --&gt;|有經驗| Fast[直接進入 CIFAR-10]

    Week1 --&gt; Week1a[認識 MNIST 資料集]
    Week1 --&gt; Week1b[了解 Keras 框架]
    Week1 --&gt; Week1c[實作 LeNet-5]
    Week1c --&gt; Check1{準確率 &gt; 98%?}

    Check1 --&gt;|否| Debug1[除錯與優化]
    Check1 --&gt;|是| Week2[Week 3-4: 進階技術]
    Debug1 --&gt; Week1c

    Week2 --&gt; Week2a[學習 PyTorch 框架]
    Week2 --&gt; Week2b[實作 SimpleCNN]
    Week2 --&gt; Week2c[理解訓練迴圈]
    Week2c --&gt; Check2{準確率 &gt; 99%?}

    Check2 --&gt;|否| Debug2[調整超參數]
    Check2 --&gt;|是| Week3[Week 5-6: CIFAR-10 挑戰]
    Debug2 --&gt; Week2b

    Week3 --&gt; Week3a[資料增強技術]
    Week3 --&gt; Week3b[進階 CNN 架構]
    Week3 --&gt; Week3c[學習率調度]
    Week3c --&gt; Check3{準確率 &gt; 85%?}

    Check3 --&gt;|否| Debug3[模型優化]
    Check3 --&gt;|是| Advanced[進階挑戰]
    Debug3 --&gt; Week3b

    Fast --&gt; Advanced

    Advanced --&gt; Adv1[CIFAR-100]
    Advanced --&gt; Adv2[ResNet/DenseNet]
    Advanced --&gt; Adv3[遷移學習]
    Advanced --&gt; Adv4[實際應用]

    Adv1 --&gt; Master([成為 CNN 專家])
    Adv2 --&gt; Master
    Adv3 --&gt; Master
    Adv4 --&gt; Master

    style Start fill:#90EE90
    style Master fill:#FFD700
    style Check1 fill:#FFE4B5
    style Check2 fill:#FFE4B5
    style Check3 fill:#FFE4B5
    style Debug1 fill:#FFB6C1
    style Debug2 fill:#FFB6C1
    style Debug3 fill:#FFB6C1
</div>
<h2>CNN 架構演進圖</h2>
<div class="mermaid">
timeline
    title CNN 發展歷程與本指南涵蓋內容
    1998 : LeNet-5 (本指南 Part 2)
         : MNIST 資料集發布
         : 準確率 99.05%
    2009 : CIFAR-10 資料集發布
         : AlexNet 前身技術
    2012 : AlexNet (ImageNet)
         : 深度學習革命開始
         : 準確率 Top-5 84.6%
    2014 : VGGNet (本指南 Part 4 參考)
         : 更深的網路 (16-19 層)
         : CIFAR-10 準確率 92%
    2015 : ResNet
         : 殘差連接
         : CIFAR-10 準確率 93%
    2016-2020 : DenseNet, EfficientNet
              : CIFAR-10 準確率 96-98%
    2020-2025 : Vision Transformer
              : 注意力機制
              : CIFAR-10 準確率 99%+
</div>
<h2>技術架構圖</h2>
<div class="mermaid">
graph LR
    subgraph 資料準備
        A[原始影像] --&gt; B[前處理]
        B --&gt; C[正規化]
        C --&gt; D[資料增強]
    end

    subgraph CNN 模型
        D --&gt; E[卷積層 Conv2D]
        E --&gt; F[激活函數 ReLU]
        F --&gt; G[池化層 Pooling]
        G --&gt; H[Dropout]
        H --&gt; I[全連接層 Dense]
        I --&gt; J[輸出層 Softmax]
    end

    subgraph 訓練流程
        J --&gt; K[損失計算]
        K --&gt; L[反向傳播]
        L --&gt; M[優化器更新]
        M --&gt; N{收斂?}
        N --&gt;|否| E
        N --&gt;|是| O[最終模型]
    end

    subgraph 評估
        O --&gt; P[測試集評估]
        P --&gt; Q[混淆矩陣]
        P --&gt; R[準確率指標]
    end

    style E fill:#FFE4B5
    style F fill:#FFE4B5
    style G fill:#FFE4B5
    style I fill:#87CEEB
    style J fill:#90EE90
    style K fill:#FFB6C1
    style L fill:#FFB6C1
</div>
<hr />
<h2>互動式 CNN 視覺化工具：CNN Explainer</h2>
<p>為了更直觀地理解 CNN 的內部運作機制，強烈推薦使用 <strong>CNN Explainer</strong> 這個互動式網頁工具。它能讓你動手操作，觀察每個層的變化。</p>
<ul>
<li><strong>網站連結</strong>：<a href="https://poloclub.github.io/cnn-explainer/">CNN Explainer</a></li>
</ul>
<h3>主要特色</h3>
<ul>
<li><strong>互動式網路圖</strong>：視覺化 CNN 架構，點擊或懸停在不同層和神經元上，即可查看其操作和激活圖 (Activation Maps)。</li>
<li><strong>顏色編碼激活圖</strong>：神經元輸出（激活圖）以紅藍色標示，卷積核權重和偏差則以黃綠色標示，幫助理解數值及其影響。</li>
<li><strong>互動式公式視圖</strong>：點擊神經元或懸停在卷積核/偏差上，可查看具體數值並理解底層數學運算。</li>
<li><strong>超參數視覺化</strong>：直觀解釋 Padding、卷積核大小 (Kernel Size)、步幅 (Stride) 等超參數如何影響層的維度和特徵提取。</li>
<li><strong>逐步操作演示</strong>：視覺化展示卷積和最大池化等操作的過程，包括卷積核在輸入上滑動，並突出顯示選定值。</li>
<li><strong>上傳自訂影像</strong>：使用者可上傳自己的影像，觀察 CNN 如何分類，並分析整個網路的激活圖。</li>
</ul>
<h3>如何使用 CNN Explainer 學習參數</h3>
<p>在 CNN Explainer 網站中，你可以嘗試調整以下關鍵參數（Hyperparameters），觀察它們如何改變模型的行為與輸出：</p>
<h4>1. Kernel Size (卷積核大小)</h4>
<ul>
<li><strong>意義</strong>：卷積核（Filter）是一個在輸入影像上滑動的小視窗。它的尺寸決定了每次觀察影像的局部區域大小。</li>
<li><strong>網站操作</strong>：觀察不同層的卷積核（例如 3x3 或 5x5）。</li>
<li><strong>視覺效果</strong>：較大的卷積核（如 5x5）能捕捉更大範圍的特徵，但計算量也更大；較小的卷積核（如 3x3）則專注於更細微的細節。你可以在「Interactive Formula View」中看到卷積核如何與輸入像素進行乘法與加法運算。</li>
</ul>
<h4>2. Padding (填充)</h4>
<ul>
<li><strong>意義</strong>：在輸入影像的邊緣補上額外的像素（通常是 0），目的是讓輸出的特徵圖（Feature Map）保持與輸入相同的大小。</li>
<li><strong>網站操作</strong>：觀察卷積運算時，邊緣像素的處理方式。</li>
<li><strong>視覺效果</strong>：如果沒有 Padding（Valid Padding），你會發現輸出特徵圖比輸入影像小（例如 32x32 變成 30x30）。如果有 Padding（Same Padding），網站會顯示輸入影像周圍多了一圈「虛擬」的像素，使得輸出尺寸維持不變。這對於深層網路非常重要，避免影像越變越小直到消失。</li>
</ul>
<h4>3. Stride (步幅)</h4>
<ul>
<li><strong>意義</strong>：卷積核每次滑動的距離。</li>
<li><strong>網站操作</strong>：觀察卷積核滑動的速度與跨度。</li>
<li><strong>視覺效果</strong>：<ul>
<li><strong>Stride = 1</strong>：卷積核每次只移動一格，輸出特徵圖保留最多細節。</li>
<li><strong>Stride = 2</strong>：卷積核每次移動兩格，跳過中間的像素。你會發現輸出的特徵圖尺寸直接減半（例如從 32x32 變成 16x16）。這是一種在卷積層中直接進行降維（Downsampling）的常見手法。</li>
</ul>
</li>
</ul>
<p>透過在 CNN Explainer 上實際點擊與觀察，你可以不再只是死記公式，而是真正「看見」這些參數如何一步步將原始影像轉換為最後的分類結果。</p>
<hr />
<h2>本文件內容（Part 1）</h2>
<ul>
<li><a href="#學習路徑視覺化">學習路徑視覺化</a></li>
<li><a href="#第零部分基礎知識">第零部分：基礎知識</a></li>
<li><a href="#認識-mnist-資料集">認識 MNIST 資料集</a></li>
<li><a href="#認識-cifar-10-資料集">認識 CIFAR-10 資料集</a></li>
<li><a href="#深度學習框架比較-keras-vs-pytorch">深度學習框架比較</a></li>
<li><a href="#專有名詞對照表">專有名詞對照表</a></li>
<li><a href="#第一部分google-colab-環境設置">第一部分：Google Colab 環境設置</a></li>
<li><a href="#第二部分mnist--lenet-5-keras">第二部分：MNIST + LeNet-5 (Keras)</a></li>
</ul>
<h2>系列其他部分</h2>
<ul>
<li><strong>Part 2</strong> (<code>CNN_intro_b07_part2.md</code>)：第三部分 MNIST + SimpleCNN (PyTorch)</li>
<li><strong>Part 3</strong> (<code>CNN_intro_b07_part3.md</code>)：第四部分 CIFAR-10 進階實戰</li>
<li><strong>Part 4</strong> (<code>CNN_intro_b07_part4.md</code>)：第五部分 實戰技巧與完整總結</li>
</ul>
<hr />
<h2>第零部分：基礎知識</h2>
<h3>專有名詞對照表</h3>
<p>在開始之前，先熟悉本指南中會用到的專有名詞：</p>
<table>
<thead>
<tr>
<th>中文</th>
<th>英文</th>
<th>簡要說明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>卷積神經網路</strong></td>
<td>Convolutional Neural Network (CNN)</td>
<td>專門用於影像處理的神經網路</td>
</tr>
<tr>
<td><strong>卷積層</strong></td>
<td>Convolutional Layer</td>
<td>提取影像特徵的核心層</td>
</tr>
<tr>
<td><strong>卷積核/濾波器</strong></td>
<td>Kernel / Filter</td>
<td>用於提取特徵的小矩陣</td>
</tr>
<tr>
<td><strong>特徵圖</strong></td>
<td>Feature Map</td>
<td>卷積層輸出的結果</td>
</tr>
<tr>
<td><strong>池化層</strong></td>
<td>Pooling Layer</td>
<td>降低維度、保留重要特徵</td>
</tr>
<tr>
<td><strong>最大池化</strong></td>
<td>Max Pooling</td>
<td>取區域內最大值</td>
</tr>
<tr>
<td><strong>平均池化</strong></td>
<td>Average Pooling</td>
<td>取區域內平均值</td>
</tr>
<tr>
<td><strong>全連接層</strong></td>
<td>Fully Connected Layer / Dense Layer</td>
<td>傳統神經網路層</td>
</tr>
<tr>
<td><strong>激活函數</strong></td>
<td>Activation Function</td>
<td>引入非線性</td>
</tr>
<tr>
<td><strong>ReLU</strong></td>
<td>Rectified Linear Unit</td>
<td>現代最常用激活函數 f(x)=max(0,x)</td>
</tr>
<tr>
<td><strong>Sigmoid</strong></td>
<td>Sigmoid Function</td>
<td>S 型激活函數，輸出 0-1</td>
</tr>
<tr>
<td><strong>Softmax</strong></td>
<td>Softmax Function</td>
<td>多分類輸出層，輸出機率分布</td>
</tr>
<tr>
<td><strong>Dropout</strong></td>
<td>Dropout</td>
<td>隨機丟棄神經元，防止過擬合</td>
</tr>
<tr>
<td><strong>批次正規化</strong></td>
<td>Batch Normalization (BN)</td>
<td>正規化每層輸入，加速訓練</td>
</tr>
<tr>
<td><strong>正規化</strong></td>
<td>Normalization</td>
<td>將資料縮放到特定範圍</td>
</tr>
<tr>
<td><strong>標準化</strong></td>
<td>Standardization</td>
<td>轉換為均值 0、標準差 1</td>
</tr>
<tr>
<td><strong>One-Hot 編碼</strong></td>
<td>One-Hot Encoding</td>
<td>類別轉換為向量形式</td>
</tr>
<tr>
<td><strong>損失函數</strong></td>
<td>Loss Function</td>
<td>衡量預測與真實值的差異</td>
</tr>
<tr>
<td><strong>交叉熵</strong></td>
<td>Cross-Entropy</td>
<td>分類問題常用損失函數</td>
</tr>
<tr>
<td><strong>優化器</strong></td>
<td>Optimizer</td>
<td>更新模型參數的演算法</td>
</tr>
<tr>
<td><strong>Adam</strong></td>
<td>Adaptive Moment Estimation</td>
<td>自適應學習率優化器</td>
</tr>
<tr>
<td><strong>SGD</strong></td>
<td>Stochastic Gradient Descent</td>
<td>隨機梯度下降</td>
</tr>
<tr>
<td><strong>學習率</strong></td>
<td>Learning Rate</td>
<td>參數更新步長</td>
</tr>
<tr>
<td><strong>Epoch</strong></td>
<td>Epoch</td>
<td>完整訓練資料集一次</td>
</tr>
<tr>
<td><strong>Batch</strong></td>
<td>Batch</td>
<td>一次訓練的小批次資料</td>
</tr>
<tr>
<td><strong>前向傳播</strong></td>
<td>Forward Propagation</td>
<td>輸入→輸出的計算過程</td>
</tr>
<tr>
<td><strong>反向傳播</strong></td>
<td>Backpropagation</td>
<td>計算梯度並更新參數</td>
</tr>
<tr>
<td><strong>梯度</strong></td>
<td>Gradient</td>
<td>損失函數對參數的偏導數</td>
</tr>
<tr>
<td><strong>過擬合</strong></td>
<td>Overfitting</td>
<td>模型過度擬合訓練資料</td>
</tr>
<tr>
<td><strong>欠擬合</strong></td>
<td>Underfitting</td>
<td>模型學習不足</td>
</tr>
<tr>
<td><strong>資料增強</strong></td>
<td>Data Augmentation</td>
<td>透過變換產生更多訓練資料</td>
</tr>
<tr>
<td><strong>遷移學習</strong></td>
<td>Transfer Learning</td>
<td>使用預訓練模型</td>
</tr>
<tr>
<td><strong>超參數</strong></td>
<td>Hyperparameter</td>
<td>需手動設定的參數（如學習率）</td>
</tr>
<tr>
<td><strong>張量</strong></td>
<td>Tensor</td>
<td>多維陣列</td>
</tr>
<tr>
<td><strong>通道</strong></td>
<td>Channel</td>
<td>彩色影像的 RGB 三個通道</td>
</tr>
<tr>
<td><strong>步幅</strong></td>
<td>Stride</td>
<td>卷積核移動步長</td>
</tr>
<tr>
<td><strong>填充</strong></td>
<td>Padding</td>
<td>在影像邊緣填充像素</td>
</tr>
<tr>
<td><strong>感受野</strong></td>
<td>Receptive Field</td>
<td>神經元能「看到」的輸入區域</td>
</tr>
</tbody>
</table>
<h3>認識 MNIST 資料集</h3>
<h4>什麼是 MNIST？</h4>
<p><strong>MNIST (Modified National Institute of Standards and Technology database)</strong> 是最經典、最廣泛使用的手寫數字影像資料集，被稱為電腦視覺領域的「Hello World」。</p>
<h4>資料集基本資訊</h4>
<table>
<thead>
<tr>
<th>項目</th>
<th>詳細資訊</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>發布時間</strong></td>
<td>1998 年</td>
</tr>
<tr>
<td><strong>創建者</strong></td>
<td>Yann LeCun 等人</td>
</tr>
<tr>
<td><strong>資料來源</strong></td>
<td>美國國家標準與技術研究所 (NIST)</td>
</tr>
<tr>
<td><strong>訓練集大小</strong></td>
<td>60,000 張影像</td>
</tr>
<tr>
<td><strong>測試集大小</strong></td>
<td>10,000 張影像</td>
</tr>
<tr>
<td><strong>影像尺寸</strong></td>
<td>28×28 像素</td>
</tr>
<tr>
<td><strong>影像類型</strong></td>
<td>灰階（單通道）</td>
</tr>
<tr>
<td><strong>像素值範圍</strong></td>
<td>0-255（0=黑色，255=白色）</td>
</tr>
<tr>
<td><strong>類別數量</strong></td>
<td>10 類（數字 0-9）</td>
</tr>
<tr>
<td><strong>每類別訓練樣本</strong></td>
<td>約 6,000 張</td>
</tr>
<tr>
<td><strong>檔案大小</strong></td>
<td>約 11 MB（壓縮後）</td>
</tr>
<tr>
<td><strong>官方網站</strong></td>
<td>http://yann.lecun.com/exdb/mnist/</td>
</tr>
</tbody>
</table>
<h4>資料集結構</h4>
<div class="codehilite"><pre><span></span><code>MNIST 資料集
├── 訓練集 (60,000 張)
│   ├── 數字 0: 5,923 張
│   ├── 數字 1: 6,742 張
│   ├── 數字 2: 5,958 張
│   ├── 數字 3: 6,131 張
│   ├── 數字 4: 5,842 張
│   ├── 數字 5: 5,421 張
│   ├── 數字 6: 5,918 張
│   ├── 數字 7: 6,265 張
│   ├── 數字 8: 5,851 張
│   └── 數字 9: 5,949 張
│
└── 測試集 (10,000 張)
    ├── 數字 0: 980 張
    ├── 數字 1: 1,135 張
    ├── 數字 2: 1,032 張
    ├── 數字 3: 1,010 張
    ├── 數字 4: 982 張
    ├── 數字 5: 892 張
    ├── 數字 6: 958 張
    ├── 數字 7: 1,028 張
    ├── 數字 8: 974 張
    └── 數字 9: 1,009 張
</code></pre></div>

<h4>影像範例與特性</h4>
<div class="codehilite"><pre><span></span><code><span class="c1"># 在 Colab 中視覺化 MNIST</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># 載入資料</span>
<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># 顯示資料集資訊</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;MNIST 資料集資訊&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;訓練集影像形狀: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># (60000, 28, 28)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;訓練集標籤形狀: </span><span class="si">{</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># (60000,)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;測試集影像形狀: </span><span class="si">{</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>   <span class="c1"># (10000, 28, 28)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;測試集標籤形狀: </span><span class="si">{</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>   <span class="c1"># (10000,)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;像素值範圍: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2"> ~ </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;資料類型: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 統計每個類別的數量</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">訓練集各類別分布:&quot;</span><span class="p">)</span>
<span class="n">unique</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">digit</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unique</span><span class="p">,</span> <span class="n">counts</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  數字 </span><span class="si">{</span><span class="n">digit</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> 張&quot;</span><span class="p">)</span>

<span class="c1"># 視覺化範例</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;MNIST 手寫數字範例 (每行一個數字)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>  <span class="c1"># 10 個數字</span>
    <span class="c1"># 找出該數字的索引</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train</span> <span class="o">==</span> <span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>  <span class="c1"># 每個數字顯示 5 個範例</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;數字 </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 顯示單張影像的細節</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;單張影像詳細資訊&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="n">sample_idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;標籤: </span><span class="si">{</span><span class="n">y_train</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;影像形狀: </span><span class="si">{</span><span class="n">X_train</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;像素矩陣 (部分):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">][:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">])</span>  <span class="c1"># 顯示左上角 5×5 區域</span>
</code></pre></div>

<p><strong>輸出範例</strong>：</p>
<div class="codehilite"><pre><span></span><code>============================================================
MNIST 資料集資訊
============================================================
訓練集影像形狀: (60000, 28, 28)
訓練集標籤形狀: (60000,)
測試集影像形狀: (10000, 28, 28)
測試集標籤形狀: (10000,)
像素值範圍: 0 ~ 255
資料類型: uint8

訓練集各類別分布:
  數字 0: 5,923 張
  數字 1: 6,742 張
  數字 2: 5,958 張
  數字 3: 6,131 張
  數字 4: 5,842 張
  數字 5: 5,421 張
  數字 6: 5,918 張
  數字 7: 6,265 張
  數字 8: 5,851 張
  數字 9: 5,949 張
</code></pre></div>

<h4>MNIST 的特點與挑戰</h4>
<p><strong>特點</strong>：<br />
1. <strong>資料量適中</strong>：6 萬張訓練資料，足夠訓練但不會太慢<br />
2. <strong>影像簡單</strong>：28×28 灰階，計算量小<br />
3. <strong>類別平衡</strong>：每個數字約 6,000 張，分布均勻<br />
4. <strong>預處理完善</strong>：影像已經過中心化、正規化處理<br />
5. <strong>難度適中</strong>：適合入門學習</p>
<p><strong>挑戰</strong>：<br />
1. <strong>筆跡差異</strong>：不同人的書寫風格差異大<br />
2. <strong>形狀相似</strong>：某些數字容易混淆（如 4 和 9、3 和 8）<br />
3. <strong>筆畫粗細</strong>：線條粗細不一<br />
4. <strong>位置偏移</strong>：雖然已中心化，但仍有微小偏移</p>
<h4>MNIST 在研究中的地位</h4>
<p><strong>歷史意義</strong>：<br />
- 1998 年與 LeNet-5 一起發布<br />
- 推動了深度學習在影像辨識的應用<br />
- 成為評估新演算法的標準基準</p>
<p><strong>現代使用</strong>：<br />
- <strong>教學用途</strong>：最佳的深度學習入門資料集<br />
- <strong>演算法驗證</strong>：快速驗證新方法的可行性<br />
- <strong>基準測試</strong>：雖然已「過時」（太簡單），但仍作為最基礎的測試</p>
<p><strong>準確率里程碑</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="mf">1998</span><span class="w">  </span><span class="nb">LeN</span><span class="n">et</span><span class="o">-</span><span class="mf">5</span><span class="w">         </span><span class="mf">99.05</span><span class="err">%</span><span class="w">  </span><span class="p">(</span><span class="n">卷積神經網路</span><span class="p">)</span>
<span class="mf">2012</span><span class="w">  </span><span class="n">超越人類</span><span class="w">         </span><span class="mf">99.20</span><span class="err">%</span>
<span class="mf">2013</span><span class="w">  </span><span class="n">DropConnect</span><span class="w">      </span><span class="mf">99.79</span><span class="err">%</span><span class="w">  </span><span class="p">(</span><span class="n">正規化技術</span><span class="p">)</span>
<span class="mf">2016</span><span class="w">  </span><span class="n">達到極限</span><span class="w">         </span><span class="mf">99.79</span><span class="err">%</span><span class="w">  </span><span class="p">(</span><span class="n">接近理論上限</span><span class="p">)</span>

<span class="n">人類表現</span><span class="p">:</span><span class="w"> </span><span class="n">約</span><span class="w"> </span><span class="mf">99.8</span><span class="err">%</span>
<span class="n">理論上限</span><span class="p">:</span><span class="w"> </span><span class="n">約</span><span class="w"> </span><span class="mf">99.8</span><span class="err">%</span><span class="w"> </span><span class="p">(</span><span class="n">部分影像連人類也難以辨識</span><span class="p">)</span>
</code></pre></div>

<h4>如何下載與使用</h4>
<p><strong>方法 1: 透過 Keras（推薦）</strong></p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">mnist</span>

<span class="c1"># 自動下載並載入</span>
<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># 優點：一行搞定、自動快取、格式統一</span>
</code></pre></div>

<p><strong>方法 2: 透過 PyTorch</strong></p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span>

<span class="c1"># 下載訓練集</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span>      <span class="c1"># 儲存路徑</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>         <span class="c1"># 訓練集</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span>       <span class="c1"># 自動下載</span>
<span class="p">)</span>

<span class="c1"># 下載測試集</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</code></pre></div>

<p><strong>方法 3: 手動下載</strong></p>
<div class="codehilite"><pre><span></span><code><span class="err">官方網站</span><span class="o">:</span><span class="w"> </span><span class="n">http</span><span class="o">://</span><span class="n">yann</span><span class="o">.</span><span class="na">lecun</span><span class="o">.</span><span class="na">com</span><span class="sr">/exdb/mnist/</span>

<span class="err">檔案列表</span><span class="o">:</span>
<span class="o">-</span><span class="w"> </span><span class="n">train</span><span class="o">-</span><span class="n">images</span><span class="o">-</span><span class="n">idx3</span><span class="o">-</span><span class="n">ubyte</span><span class="o">.</span><span class="na">gz</span><span class="w">  </span><span class="o">(</span><span class="err">訓練影像</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">train</span><span class="o">-</span><span class="n">labels</span><span class="o">-</span><span class="n">idx1</span><span class="o">-</span><span class="n">ubyte</span><span class="o">.</span><span class="na">gz</span><span class="w">  </span><span class="o">(</span><span class="err">訓練標籤</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">t10k</span><span class="o">-</span><span class="n">images</span><span class="o">-</span><span class="n">idx3</span><span class="o">-</span><span class="n">ubyte</span><span class="o">.</span><span class="na">gz</span><span class="w">   </span><span class="o">(</span><span class="err">測試影像</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">t10k</span><span class="o">-</span><span class="n">labels</span><span class="o">-</span><span class="n">idx1</span><span class="o">-</span><span class="n">ubyte</span><span class="o">.</span><span class="na">gz</span><span class="w">   </span><span class="o">(</span><span class="err">測試標籤</span><span class="o">)</span>
</code></pre></div>

<hr />
<h3>認識 CIFAR-10 資料集</h3>
<h4>什麼是 CIFAR-10？</h4>
<p><strong>CIFAR-10 (Canadian Institute For Advanced Research)</strong> 是一個彩色影像分類資料集，包含 10 個類別的自然物體影像。相比 MNIST，CIFAR-10 更接近真實世界的影像識別任務。</p>
<h4>資料集基本資訊</h4>
<table>
<thead>
<tr>
<th>項目</th>
<th>詳細資訊</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>發布時間</strong></td>
<td>2009 年</td>
</tr>
<tr>
<td><strong>創建者</strong></td>
<td>Alex Krizhevsky, Vinod Nair, Geoffrey Hinton</td>
</tr>
<tr>
<td><strong>資料來源</strong></td>
<td>8000 萬張微型影像資料集（80 million tiny images）</td>
</tr>
<tr>
<td><strong>訓練集大小</strong></td>
<td>50,000 張影像</td>
</tr>
<tr>
<td><strong>測試集大小</strong></td>
<td>10,000 張影像</td>
</tr>
<tr>
<td><strong>影像尺寸</strong></td>
<td>32×32 像素</td>
</tr>
<tr>
<td><strong>影像類型</strong></td>
<td>彩色（RGB，3 通道）</td>
</tr>
<tr>
<td><strong>像素值範圍</strong></td>
<td>0-255（每個通道）</td>
</tr>
<tr>
<td><strong>類別數量</strong></td>
<td>10 類</td>
</tr>
<tr>
<td><strong>每類別訓練樣本</strong></td>
<td>5,000 張（完全平衡）</td>
</tr>
<tr>
<td><strong>檔案大小</strong></td>
<td>約 170 MB</td>
</tr>
<tr>
<td><strong>官方網站</strong></td>
<td>https://www.cs.toronto.edu/~kriz/cifar.html</td>
</tr>
</tbody>
</table>
<h4>10 個類別詳細介紹</h4>
<table>
<thead>
<tr>
<th>編號</th>
<th>類別名稱</th>
<th>中文</th>
<th>範例</th>
<th>挑戰</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>airplane</td>
<td>飛機</td>
<td>客機、戰鬥機、直升機</td>
<td>天空背景、視角變化</td>
</tr>
<tr>
<td>1</td>
<td>automobile</td>
<td>汽車</td>
<td>轎車、貨車、巴士</td>
<td>顏色多樣、與 truck 相似</td>
</tr>
<tr>
<td>2</td>
<td>bird</td>
<td>鳥</td>
<td>各種鳥類</td>
<td>羽毛紋理、與背景融合</td>
</tr>
<tr>
<td>3</td>
<td>cat</td>
<td>貓</td>
<td>各品種的貓</td>
<td>與 dog 相似、姿態多變</td>
</tr>
<tr>
<td>4</td>
<td>deer</td>
<td>鹿</td>
<td>各種鹿科動物</td>
<td>與 horse 相似、背景複雜</td>
</tr>
<tr>
<td>5</td>
<td>dog</td>
<td>狗</td>
<td>各品種的狗</td>
<td>品種差異大、與 cat 相似</td>
</tr>
<tr>
<td>6</td>
<td>frog</td>
<td>青蛙</td>
<td>各種蛙類</td>
<td>小、與背景顏色接近</td>
</tr>
<tr>
<td>7</td>
<td>horse</td>
<td>馬</td>
<td>馬</td>
<td>與 deer 相似、姿態多變</td>
</tr>
<tr>
<td>8</td>
<td>ship</td>
<td>船</td>
<td>各種船隻</td>
<td>水面反射、視角變化</td>
</tr>
<tr>
<td>9</td>
<td>truck</td>
<td>卡車</td>
<td>卡車、貨車</td>
<td>與 automobile 相似</td>
</tr>
</tbody>
</table>
<h4>資料集結構</h4>
<div class="codehilite"><pre><span></span><code>CIFAR-10 資料集
├── 訓練集 (50,000 張，5 個批次)
│   ├── data_batch_1: 10,000 張
│   ├── data_batch_2: 10,000 張
│   ├── data_batch_3: 10,000 張
│   ├── data_batch_4: 10,000 張
│   └── data_batch_5: 10,000 張
│
└── 測試集 (10,000 張)
    └── test_batch: 10,000 張

每個類別:
├── 訓練集: 5,000 張 (完全平衡)
└── 測試集: 1,000 張 (完全平衡)
</code></pre></div>

<h4>影像範例與視覺化</h4>
<div class="codehilite"><pre><span></span><code><span class="c1"># 在 Colab 中視覺化 CIFAR-10</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">cifar10</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># 載入資料</span>
<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># 類別名稱</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;airplane&#39;</span><span class="p">,</span> <span class="s1">&#39;automobile&#39;</span><span class="p">,</span> <span class="s1">&#39;bird&#39;</span><span class="p">,</span> <span class="s1">&#39;cat&#39;</span><span class="p">,</span> <span class="s1">&#39;deer&#39;</span><span class="p">,</span>
               <span class="s1">&#39;dog&#39;</span><span class="p">,</span> <span class="s1">&#39;frog&#39;</span><span class="p">,</span> <span class="s1">&#39;horse&#39;</span><span class="p">,</span> <span class="s1">&#39;ship&#39;</span><span class="p">,</span> <span class="s1">&#39;truck&#39;</span><span class="p">]</span>
<span class="n">class_names_zh</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;飛機&#39;</span><span class="p">,</span> <span class="s1">&#39;汽車&#39;</span><span class="p">,</span> <span class="s1">&#39;鳥&#39;</span><span class="p">,</span> <span class="s1">&#39;貓&#39;</span><span class="p">,</span> <span class="s1">&#39;鹿&#39;</span><span class="p">,</span>
                  <span class="s1">&#39;狗&#39;</span><span class="p">,</span> <span class="s1">&#39;青蛙&#39;</span><span class="p">,</span> <span class="s1">&#39;馬&#39;</span><span class="p">,</span> <span class="s1">&#39;船&#39;</span><span class="p">,</span> <span class="s1">&#39;卡車&#39;</span><span class="p">]</span>

<span class="c1"># 顯示資料集資訊</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;CIFAR-10 資料集資訊&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;訓練集影像形狀: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># (50000, 32, 32, 3)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;訓練集標籤形狀: </span><span class="si">{</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># (50000, 1)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;測試集影像形狀: </span><span class="si">{</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>   <span class="c1"># (10000, 32, 32, 3)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;測試集標籤形狀: </span><span class="si">{</span><span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>   <span class="c1"># (10000, 1)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;像素值範圍: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2"> ~ </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;資料類型: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;影像通道數: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="si">}</span><span class="s2"> (RGB)&quot;</span><span class="p">)</span>

<span class="c1"># 統計每個類別的數量</span>
<span class="n">y_train_flat</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">訓練集各類別分布:&quot;</span><span class="p">)</span>
<span class="n">unique</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train_flat</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">digit</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unique</span><span class="p">,</span> <span class="n">counts</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">digit</span><span class="p">]</span><span class="si">:</span><span class="s2">12s</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">class_names_zh</span><span class="p">[</span><span class="n">digit</span><span class="p">]</span><span class="si">}</span><span class="s2">): </span><span class="si">{</span><span class="n">count</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> 張&quot;</span><span class="p">)</span>

<span class="c1"># 視覺化：每個類別顯示 10 個範例</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;CIFAR-10 影像範例 (每行一個類別)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>  <span class="c1"># 10 個類別</span>
    <span class="c1"># 找出該類別的索引</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_train_flat</span> <span class="o">==</span> <span class="n">i</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>  <span class="c1"># 每個類別顯示 10 個範例</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">class_names_zh</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                         <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 顯示單張影像的細節</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;單張影像詳細資訊&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="n">sample_idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;標籤: </span><span class="si">{</span><span class="n">y_train</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">class_names</span><span class="p">[</span><span class="n">y_train</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">][</span><span class="mi">0</span><span class="p">]]</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;影像形狀: </span><span class="si">{</span><span class="n">X_train</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;RGB 三個通道的像素範圍:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  R 通道: </span><span class="si">{</span><span class="n">X_train</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">][:,:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2"> ~ </span><span class="si">{</span><span class="n">X_train</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">][:,:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  G 通道: </span><span class="si">{</span><span class="n">X_train</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">][:,:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2"> ~ </span><span class="si">{</span><span class="n">X_train</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">][:,:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  B 通道: </span><span class="si">{</span><span class="n">X_train</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">][:,:,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">}</span><span class="s2"> ~ </span><span class="si">{</span><span class="n">X_train</span><span class="p">[</span><span class="n">sample_idx</span><span class="p">][:,:,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 計算並顯示資料集統計資訊</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">資料集統計資訊 (用於標準化):&quot;</span><span class="p">)</span>
<span class="n">mean_r</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,:,:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">mean_g</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,:,:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">mean_b</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,:,:,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">std_r</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,:,:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">std_g</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,:,:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">std_b</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,:,:,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">/</span> <span class="mi">255</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  均值 (Mean): [</span><span class="si">{</span><span class="n">mean_r</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">mean_g</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">mean_b</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  標準差 (Std): [</span><span class="si">{</span><span class="n">std_r</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">std_g</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">std_b</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>輸出範例</strong>：</p>
<div class="codehilite"><pre><span></span><code>============================================================
CIFAR-10 資料集資訊
============================================================
訓練集影像形狀: (50000, 32, 32, 3)
訓練集標籤形狀: (50000, 1)
測試集影像形狀: (10000, 32, 32, 3)
測試集標籤形狀: (10000, 1)
像素值範圍: 0 ~ 255
資料類型: uint8
影像通道數: 3 (RGB)

訓練集各類別分布:
  airplane     (飛機): 5,000 張
  automobile   (汽車): 5,000 張
  bird         (鳥): 5,000 張
  cat          (貓): 5,000 張
  deer         (鹿): 5,000 張
  dog          (狗): 5,000 張
  frog         (青蛙): 5,000 張
  horse        (馬): 5,000 張
  ship         (船): 5,000 張
  truck        (卡車): 5,000 張

資料集統計資訊 (用於標準化):
  均值 (Mean): [0.4914, 0.4822, 0.4465]
  標準差 (Std): [0.2470, 0.2435, 0.2616]
</code></pre></div>

<h4>CIFAR-10 的特點與挑戰</h4>
<p><strong>特點</strong>：<br />
1. <strong>彩色影像</strong>：RGB 三通道，更接近真實世界<br />
2. <strong>類別多樣</strong>：動物、交通工具等不同類型<br />
3. <strong>資料平衡</strong>：每類別完全相同數量<br />
4. <strong>尺寸較小</strong>：32×32，訓練速度快<br />
5. <strong>難度適中</strong>：比 MNIST 難，但仍可處理</p>
<p><strong>挑戰</strong>：<br />
1. <strong>影像解析度低</strong>：32×32 很小，細節不足<br />
2. <strong>背景複雜</strong>：自然影像包含複雜背景<br />
3. <strong>類內變異大</strong>：同類別物體差異大（如不同品種的狗）<br />
4. <strong>類間相似</strong>：某些類別容易混淆<br />
   - cat vs dog（最容易混淆）<br />
   - automobile vs truck<br />
   - deer vs horse<br />
5. <strong>視角變化</strong>：同物體不同角度<br />
6. <strong>光照條件</strong>：不同光照、天氣</p>
<h4>MNIST vs CIFAR-10 完整對比</h4>
<table>
<thead>
<tr>
<th>特性</th>
<th>MNIST</th>
<th>CIFAR-10</th>
<th>差異說明</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>發布年份</strong></td>
<td>1998</td>
<td>2009</td>
<td>CIFAR-10 較新</td>
</tr>
<tr>
<td><strong>影像類型</strong></td>
<td>灰階（1 通道）</td>
<td>彩色（3 通道 RGB）</td>
<td>CIFAR-10 資訊量 3 倍</td>
</tr>
<tr>
<td><strong>影像尺寸</strong></td>
<td>28×28 = 784 像素</td>
<td>32×32×3 = 3,072 像素</td>
<td>CIFAR-10 約 4 倍資料</td>
</tr>
<tr>
<td><strong>訓練集</strong></td>
<td>60,000</td>
<td>50,000</td>
<td>MNIST 稍多</td>
</tr>
<tr>
<td><strong>測試集</strong></td>
<td>10,000</td>
<td>10,000</td>
<td>相同</td>
</tr>
<tr>
<td><strong>類別數</strong></td>
<td>10 (數字)</td>
<td>10 (物體)</td>
<td>相同</td>
</tr>
<tr>
<td><strong>類別平衡</strong></td>
<td>基本平衡 (5,421-6,742)</td>
<td>完全平衡 (5,000)</td>
<td>CIFAR-10 更平衡</td>
</tr>
<tr>
<td><strong>影像內容</strong></td>
<td>手寫數字</td>
<td>自然物體</td>
<td>CIFAR-10 更複雜</td>
</tr>
<tr>
<td><strong>背景</strong></td>
<td>純黑色</td>
<td>自然背景</td>
<td>CIFAR-10 有複雜背景</td>
</tr>
<tr>
<td><strong>資料來源</strong></td>
<td>掃描手寫</td>
<td>網路圖片</td>
<td>CIFAR-10 更真實</td>
</tr>
<tr>
<td><strong>預處理</strong></td>
<td>已中心化、大小統一</td>
<td>已裁剪為 32×32</td>
<td>都已預處理</td>
</tr>
<tr>
<td><strong>檔案大小</strong></td>
<td>約 11 MB</td>
<td>約 170 MB</td>
<td>CIFAR-10 大 15 倍</td>
</tr>
<tr>
<td><strong>訓練時間</strong></td>
<td>2-5 分鐘 (GPU)</td>
<td>15-30 分鐘 (GPU)</td>
<td>CIFAR-10 慢 5-10 倍</td>
</tr>
<tr>
<td><strong>入門難度</strong></td>
<td>★☆☆☆☆ (非常簡單)</td>
<td>★★★☆☆ (中等)</td>
<td>MNIST 適合入門</td>
</tr>
<tr>
<td><strong>簡單 CNN 準確率</strong></td>
<td>~99%</td>
<td>~70%</td>
<td>MNIST 容易得高分</td>
</tr>
<tr>
<td><strong>人類表現</strong></td>
<td>~99.8%</td>
<td>~94%</td>
<td>CIFAR-10 人類也會錯</td>
</tr>
<tr>
<td><strong>SOTA 準確率</strong></td>
<td>~99.79%</td>
<td>~99%+ (ViT)</td>
<td>都接近上限</td>
</tr>
<tr>
<td><strong>適用場景</strong></td>
<td>學習基礎、驗證演算法</td>
<td>研究、基準測試</td>
<td>CIFAR-10 更具挑戰性</td>
</tr>
</tbody>
</table>
<h4>CIFAR-10 的兄弟：CIFAR-100</h4>
<p>除了 CIFAR-10，還有 <strong>CIFAR-100</strong>：</p>
<table>
<thead>
<tr>
<th>項目</th>
<th>CIFAR-10</th>
<th>CIFAR-100</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>類別數</strong></td>
<td>10</td>
<td>100</td>
</tr>
<tr>
<td><strong>每類別訓練樣本</strong></td>
<td>5,000</td>
<td>500</td>
</tr>
<tr>
<td><strong>訓練集</strong></td>
<td>50,000</td>
<td>50,000</td>
</tr>
<tr>
<td><strong>難度</strong></td>
<td>中等</td>
<td>困難</td>
</tr>
<tr>
<td><strong>SOTA 準確率</strong></td>
<td>~99%</td>
<td>~90%</td>
</tr>
</tbody>
</table>
<p>CIFAR-100 的 100 個類別分為 20 個超類（superclass），每個超類包含 5 個子類。</p>
<h4>如何下載與使用</h4>
<p><strong>方法 1: 透過 Keras（推薦）</strong></p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">cifar10</span>

<span class="c1"># 自動下載並載入</span>
<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># 注意：標籤形狀是 (50000, 1)，需要 flatten</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>  <span class="c1"># (50000,)</span>
</code></pre></div>

<p><strong>方法 2: 透過 PyTorch</strong></p>
<div class="codehilite"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>

<span class="c1"># 下載訓練集</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># 下載測試集</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="p">)</span>
</code></pre></div>

<p><strong>方法 3: 手動下載</strong></p>
<div class="codehilite"><pre><span></span><code><span class="err">官方網站</span><span class="o">:</span><span class="w"> </span><span class="n">https</span><span class="o">://</span><span class="n">www</span><span class="o">.</span><span class="na">cs</span><span class="o">.</span><span class="na">toronto</span><span class="o">.</span><span class="na">edu</span><span class="sr">/~kriz/</span><span class="n">cifar</span><span class="o">.</span><span class="na">html</span>

<span class="n">Python</span><span class="w"> </span><span class="err">版本</span><span class="o">:</span>
<span class="o">-</span><span class="w"> </span><span class="n">cifar</span><span class="o">-</span><span class="mi">10</span><span class="o">-</span><span class="n">python</span><span class="o">.</span><span class="na">tar</span><span class="o">.</span><span class="na">gz</span><span class="w">  </span><span class="o">(</span><span class="mi">163</span><span class="w"> </span><span class="n">MB</span><span class="o">)</span>

<span class="err">內容</span><span class="o">:</span>
<span class="o">-</span><span class="w"> </span><span class="n">data_batch_1</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="mi">5</span><span class="w"> </span><span class="o">(</span><span class="err">訓練集</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">test_batch</span><span class="w"> </span><span class="o">(</span><span class="err">測試集</span><span class="o">)</span>
<span class="o">-</span><span class="w"> </span><span class="n">batches</span><span class="o">.</span><span class="na">meta</span><span class="w"> </span><span class="o">(</span><span class="err">元資料</span><span class="o">)</span>
</code></pre></div>

<h4>CIFAR-10 在研究中的地位</h4>
<p><strong>歷史意義</strong>：<br />
- 2009 年發布，填補了 MNIST 和 ImageNet 之間的空白<br />
- 推動了資料增強技術的發展<br />
- AlexNet (2012) 在 ImageNet 成功前，許多技術先在 CIFAR-10 上驗證</p>
<p><strong>現代使用</strong>：<br />
- <strong>研究基準</strong>：測試新架構、新技術的標準資料集<br />
- <strong>課程教學</strong>：從 MNIST 進階到 CIFAR-10<br />
- <strong>論文評估</strong>：許多論文必須在 CIFAR-10 上報告結果</p>
<p><strong>準確率里程碑</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="mf">2012</span><span class="w">  </span><span class="n">AlexNet</span><span class="w"> </span><span class="n">風格</span><span class="w">      </span><span class="err">~</span><span class="mf">80</span><span class="err">%</span><span class="w">   </span><span class="p">(</span><span class="n">深度</span><span class="w"> </span><span class="n">CNN</span><span class="p">)</span>
<span class="mf">2014</span><span class="w">  </span><span class="n">VGGNet</span><span class="w">             </span><span class="err">~</span><span class="mf">92</span><span class="err">%</span><span class="w">   </span><span class="p">(</span><span class="n">更深的網路</span><span class="p">)</span>
<span class="mf">2015</span><span class="w">  </span><span class="n">ResNet</span><span class="w">             </span><span class="err">~</span><span class="mf">93</span><span class="err">%</span><span class="w">   </span><span class="p">(</span><span class="n">殘差連接</span><span class="p">)</span>
<span class="mf">2016</span><span class="w">  </span><span class="n">DenseNet</span><span class="w">           </span><span class="err">~</span><span class="mf">96</span><span class="err">%</span><span class="w">   </span><span class="p">(</span><span class="n">密集連接</span><span class="p">)</span>
<span class="mf">2019</span><span class="w">  </span><span class="n">EfficientNet</span><span class="w">       </span><span class="err">~</span><span class="mf">98</span><span class="err">%</span><span class="w">   </span><span class="p">(</span><span class="n">複合縮放</span><span class="p">)</span>
<span class="mf">2020</span><span class="w">  </span><span class="n">Vision</span><span class="w"> </span><span class="n">Transformer</span><span class="w"> </span><span class="err">~</span><span class="mf">99</span><span class="err">%</span><span class="o">+</span><span class="w">  </span><span class="p">(</span><span class="n">Transformer</span><span class="p">)</span>

<span class="n">人類表現</span><span class="p">:</span><span class="w"> </span><span class="n">約</span><span class="w"> </span><span class="mf">94</span><span class="err">%</span>
</code></pre></div>

<hr />
<p>(檔案繼續... 由於長度限制，完整內容請參考實際檔案)</p>
<p><strong>註</strong>：此為 b07 版本的開頭部分，完整版本包含所有 Part 2-5 的完整程式碼，符合 CLAUDE.md 的完整性原則。</p>
<h3>深度學習框架比較: Keras vs PyTorch</h3>
<p>在開始實作之前，了解兩大主流深度學習框架的差異非常重要。本指南會同時使用 <strong>Keras</strong> 和 <strong>PyTorch</strong>，讓你掌握兩種工具。</p>
<h4>框架概述</h4>
<p><strong>Keras (TensorFlow)</strong></p>
<table>
<thead>
<tr>
<th>項目</th>
<th>詳細資訊</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>開發者</strong></td>
<td>François Chollet (Google)</td>
</tr>
<tr>
<td><strong>首次發布</strong></td>
<td>2015 年</td>
</tr>
<tr>
<td><strong>當前版本</strong></td>
<td>Keras 2.x / 3.x</td>
</tr>
<tr>
<td><strong>底層框架</strong></td>
<td>TensorFlow (原本支援多後端，現已整合至 TensorFlow)</td>
</tr>
<tr>
<td><strong>設計理念</strong></td>
<td>使用者友善、模組化、易於擴展</td>
</tr>
<tr>
<td><strong>定位</strong></td>
<td>TensorFlow 的高階 API</td>
</tr>
<tr>
<td><strong>官網</strong></td>
<td>https://keras.io/</td>
</tr>
<tr>
<td><strong>GitHub Stars</strong></td>
<td>~60K</td>
</tr>
</tbody>
</table>
<p><strong>PyTorch</strong></p>
<table>
<thead>
<tr>
<th>項目</th>
<th>詳細資訊</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>開發者</strong></td>
<td>Facebook AI Research (Meta)</td>
</tr>
<tr>
<td><strong>首次發布</strong></td>
<td>2016 年</td>
</tr>
<tr>
<td><strong>當前版本</strong></td>
<td>PyTorch 2.x</td>
</tr>
<tr>
<td><strong>底層框架</strong></td>
<td>自己就是底層框架</td>
</tr>
<tr>
<td><strong>設計理念</strong></td>
<td>直覺、靈活、Pythonic</td>
</tr>
<tr>
<td><strong>定位</strong></td>
<td>獨立的深度學習框架</td>
</tr>
<tr>
<td><strong>官網</strong></td>
<td>https://pytorch.org/</td>
</tr>
<tr>
<td><strong>GitHub Stars</strong></td>
<td>~70K</td>
</tr>
</tbody>
</table>
<h4>核心差異對比</h4>
<table>
<thead>
<tr>
<th>特性</th>
<th>Keras (TensorFlow)</th>
<th>PyTorch</th>
<th>推薦場景</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>學習曲線</strong></td>
<td>★☆☆☆☆ 非常簡單</td>
<td>★★☆☆☆ 簡單</td>
<td>Keras 適合初學</td>
</tr>
<tr>
<td><strong>程式碼風格</strong></td>
<td>高階 API，簡潔</td>
<td>低階控制，靈活</td>
<td>Keras 快速原型，PyTorch 自訂</td>
</tr>
<tr>
<td><strong>模型定義</strong></td>
<td>Sequential / Functional</td>
<td><code>nn.Module</code> 類別</td>
<td>各有優勢</td>
</tr>
<tr>
<td><strong>動態/靜態圖</strong></td>
<td>靜態圖（預設）<br>動態圖（Eager mode）</td>
<td>動態圖（預設）</td>
<td>PyTorch 更直覺</td>
</tr>
<tr>
<td><strong>Debug 難度</strong></td>
<td>★★★☆☆ 較難</td>
<td>★☆☆☆☆ 容易</td>
<td>PyTorch 更易除錯</td>
</tr>
<tr>
<td><strong>模型部署</strong></td>
<td>TensorFlow Serving, TFLite</td>
<td>TorchServe, ONNX</td>
<td>TF 部署生態更完善</td>
</tr>
<tr>
<td><strong>研究社群</strong></td>
<td>業界為主</td>
<td>學術界為主</td>
<td>PyTorch 在研究界更流行</td>
</tr>
<tr>
<td><strong>產品應用</strong></td>
<td>Google 產品</td>
<td>Meta 產品</td>
<td></td>
</tr>
<tr>
<td><strong>文件完整度</strong></td>
<td>★★★★★ 非常完整</td>
<td>★★★★☆ 完整</td>
<td>Keras 文件更友善</td>
</tr>
<tr>
<td><strong>中文資源</strong></td>
<td>★★★★☆ 豐富</td>
<td>★★★★☆ 豐富</td>
<td>都有豐富中文資源</td>
</tr>
<tr>
<td><strong>效能</strong></td>
<td>相當（都很快）</td>
<td>相當（都很快）</td>
<td>持平</td>
</tr>
<tr>
<td><strong>生態系統</strong></td>
<td>TensorFlow Hub, TF Extended</td>
<td>torchvision, torchaudio</td>
<td>都很完整</td>
</tr>
</tbody>
</table>
<div class="mermaid">
graph LR
    subgraph Keras優勢
        A1[簡潔語法] --&gt; A2[快速原型]
        A3[豐富文件] --&gt; A2
        A4[易於部署] --&gt; A5[生產環境]
    end

    subgraph PyTorch優勢
        B1[靈活架構] --&gt; B2[研究專案]
        B3[易於除錯] --&gt; B2
        B4[動態圖] --&gt; B5[複雜模型]
    end

    A2 -.選擇.-&gt; C{專案需求}
    B2 -.選擇.-&gt; C
    
    C --&gt;|快速開發| Keras
    C --&gt;|深入研究| PyTorch
    C --&gt;|生產部署| Keras
    C --&gt;|學術論文| PyTorch

    style A2 fill:#90EE90
    style B2 fill:#87CEEB
    style C fill:#FFE4B5
</div>
<h4>程式碼風格對比</h4>
<p><strong>範例 1: 建立簡單模型</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># ============ Keras 風格 ============</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">Flatten</span>

<span class="c1"># 使用 Sequential API（適合線性堆疊）</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Conv2D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
    <span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>

<span class="c1"># 編譯模型（一次設定所有訓練參數）</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="c1"># 訓練（一行搞定）</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>


<span class="c1"># ============ PyTorch 風格 ============</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>

<span class="c1"># 繼承 nn.Module（更靈活、物件導向）</span>
<span class="k">class</span><span class="w"> </span><span class="nc">SimpleCNN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleCNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">26</span><span class="o">*</span><span class="mi">26</span><span class="o">*</span><span class="mi">32</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># 需要手動計算維度</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Flatten</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleCNN</span><span class="p">()</span>

<span class="c1"># 需要分別定義損失函數和優化器</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="c1"># 需要手寫訓練迴圈</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_y</span> <span class="ow">in</span> <span class="n">train_loader</span><span class="p">:</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">batch_y</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</code></pre></div>

<p><strong>觀察</strong>：<br />
- Keras: 更簡潔，適合快速實作<br />
- PyTorch: 更明確，適合客製化</p>
<h4>何時選擇哪個框架？</h4>
<p><strong>選擇 Keras 的情況</strong>：</p>
<p>✅ 你是深度學習初學者<br />
✅ 需要快速實作原型<br />
✅ 專案需求較標準（常見的分類、回歸任務）<br />
✅ 重視部署便利性（TensorFlow Lite, TensorFlow.js）<br />
✅ 團隊成員技術水平不一<br />
✅ 需要豐富的預訓練模型（TensorFlow Hub）</p>
<p><strong>範例場景</strong>：<br />
- 課程作業、Kaggle 入門競賽<br />
- 快速驗證想法<br />
- 需要部署到行動裝置或網頁</p>
<p><strong>選擇 PyTorch 的情況</strong>：</p>
<p>✅ 你想深入理解深度學習原理<br />
✅ 需要高度客製化模型<br />
✅ 研究導向專案（發表論文）<br />
✅ 需要動態網路結構（RNN, Attention 等）<br />
✅ 重視程式碼可讀性和除錯便利<br />
✅ 參考最新研究論文（大多提供 PyTorch 實作）</p>
<p><strong>範例場景</strong>：<br />
- 學術研究、論文實作<br />
- 複雜的自訂模型（如 Transformer）<br />
- 需要細粒度控制訓練過程</p>
<h4>安裝與環境設置</h4>
<p><strong>Keras (TensorFlow)</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># CPU 版本</span>
pip<span class="w"> </span>install<span class="w"> </span>tensorflow

<span class="c1"># GPU 版本（自動包含 CUDA）</span>
pip<span class="w"> </span>install<span class="w"> </span>tensorflow<span class="o">[</span>and-cuda<span class="o">]</span>

<span class="c1"># 驗證安裝</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import tensorflow as tf; print(tf.__version__)&quot;</span>
</code></pre></div>

<p><strong>PyTorch</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 訪問 https://pytorch.org/ 根據系統選擇安裝指令</span>

<span class="c1"># 範例（CUDA 11.8）：</span>
pip3<span class="w"> </span>install<span class="w"> </span>torch<span class="w"> </span>torchvision<span class="w"> </span>torchaudio<span class="w"> </span>--index-url<span class="w"> </span>https://download.pytorch.org/whl/cu118

<span class="c1"># CPU 版本：</span>
pip3<span class="w"> </span>install<span class="w"> </span>torch<span class="w"> </span>torchvision<span class="w"> </span>torchaudio

<span class="c1"># 驗證安裝</span>
python<span class="w"> </span>-c<span class="w"> </span><span class="s2">&quot;import torch; print(torch.__version__); print(torch.cuda.is_available())&quot;</span>
</code></pre></div>

<p><strong>Google Colab 環境</strong>（推薦初學者）：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># Colab 已預裝 TensorFlow 和 PyTorch</span>
<span class="c1"># 直接檢查版本即可</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TensorFlow version: </span><span class="si">{</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PyTorch version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CUDA available: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<hr />
<h2>第一部分：Google Colab 環境設置</h2>
<h3>為什麼使用 Google Colab？</h3>
<p><strong>Google Colaboratory (Colab)</strong> 是 Google 提供的免費雲端 Jupyter Notebook 服務：</p>
<p><strong>主要優勢</strong>：<br />
- ✅ <strong>免費 GPU/TPU</strong>：不需要昂貴硬體<br />
- ✅ <strong>零安裝</strong>：瀏覽器直接使用<br />
- ✅ <strong>整合 Google Drive</strong>：檔案自動儲存<br />
- ✅ <strong>預裝套件</strong>：TensorFlow, PyTorch 等已安裝<br />
- ✅ <strong>分享便利</strong>：像 Google Docs 一樣分享<br />
- ✅ <strong>Jupyter Notebook</strong>：互動式開發環境</p>
<h3>步驟 1：開啟 Colab</h3>
<ol>
<li>瀏覽器前往: https://colab.research.google.com/</li>
<li>使用 Google 帳號登入</li>
<li>點選「新增筆記本」(New Notebook)</li>
</ol>
<h3>步驟 2：啟用 GPU（關鍵！）</h3>
<p><strong>為什麼需要 GPU？</strong></p>
<table>
<thead>
<tr>
<th>硬體</th>
<th>MNIST 訓練時間</th>
<th>CIFAR-10 訓練時間</th>
<th>速度比較</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>CPU</strong></td>
<td>10-15 分鐘</td>
<td>60-90 分鐘</td>
<td>基準 ×1</td>
</tr>
<tr>
<td><strong>GPU</strong></td>
<td>2-3 分鐘</td>
<td>10-15 分鐘</td>
<td>快 5-6 倍</td>
</tr>
<tr>
<td><strong>TPU</strong></td>
<td>1-2 分鐘</td>
<td>5-8 分鐘</td>
<td>快 8-10 倍</td>
</tr>
</tbody>
</table>
<p><strong>啟用步驟</strong>：</p>
<ol>
<li>點選上方選單：<strong>「執行階段」</strong> (Runtime)</li>
<li>選擇：<strong>「變更執行階段類型」</strong> (Change runtime type)</li>
<li>硬體加速器 (Hardware accelerator)：選擇 <strong>「GPU」</strong> 或 <strong>「TPU」</strong></li>
<li>點選「儲存」(Save)</li>
</ol>
<p><strong>驗證 GPU 是否啟用</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># ============================================</span>
<span class="c1"># 儲存格 0: 環境檢查</span>
<span class="c1"># ============================================</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;環境資訊&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Python 版本: </span><span class="si">{</span><span class="n">sys</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TensorFlow 版本: </span><span class="si">{</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PyTorch 版本: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;GPU 資訊&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

<span class="c1"># TensorFlow GPU</span>
<span class="n">tf_gpus</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TensorFlow 可用 GPU: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tf_gpus</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">tf_gpus</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">gpu</span> <span class="ow">in</span> <span class="n">tf_gpus</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - </span><span class="si">{</span><span class="n">gpu</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># PyTorch GPU</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">PyTorch CUDA 可用: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PyTorch GPU 型號: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;PyTorch GPU 記憶體: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">total_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">1024</span><span class="o">**</span><span class="mi">3</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB&quot;</span><span class="p">)</span>

<span class="c1"># 記憶體資訊</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;系統資源&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="err">!</span><span class="n">nvidia</span><span class="o">-</span><span class="n">smi</span> <span class="o">--</span><span class="n">query</span><span class="o">-</span><span class="n">gpu</span><span class="o">=</span><span class="n">name</span><span class="p">,</span><span class="n">memory</span><span class="o">.</span><span class="n">total</span><span class="p">,</span><span class="n">memory</span><span class="o">.</span><span class="n">free</span> <span class="o">--</span><span class="nb">format</span><span class="o">=</span><span class="n">csv</span>
</code></pre></div>

<p><strong>預期輸出</strong>（GPU 已啟用）：</p>
<div class="codehilite"><pre><span></span><code><span class="o">============================================================</span>
<span class="n">環境資訊</span>
<span class="o">============================================================</span>
<span class="n">Python</span><span class="w"> </span><span class="nl">版本</span><span class="p">:</span><span class="w"> </span><span class="mf">3.10.12</span>
<span class="n">TensorFlow</span><span class="w"> </span><span class="nl">版本</span><span class="p">:</span><span class="w"> </span><span class="mf">2.15.0</span>
<span class="n">PyTorch</span><span class="w"> </span><span class="nl">版本</span><span class="p">:</span><span class="w"> </span><span class="mf">2.1.0</span><span class="o">+</span><span class="n">cu118</span>

<span class="o">============================================================</span>
<span class="n">GPU</span><span class="w"> </span><span class="n">資訊</span>
<span class="o">============================================================</span>
<span class="n">TensorFlow</span><span class="w"> </span><span class="n">可用</span><span class="w"> </span><span class="nl">GPU</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">  </span><span class="o">-</span><span class="w"> </span><span class="n">PhysicalDevice</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;/physical_device:GPU:0&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">device_type</span><span class="o">=</span><span class="s1">&#39;GPU&#39;</span><span class="p">)</span>

<span class="n">PyTorch</span><span class="w"> </span><span class="n">CUDA</span><span class="w"> </span><span class="nl">可用</span><span class="p">:</span><span class="w"> </span><span class="k">True</span>
<span class="n">PyTorch</span><span class="w"> </span><span class="n">GPU</span><span class="w"> </span><span class="nl">型號</span><span class="p">:</span><span class="w"> </span><span class="n">Tesla</span><span class="w"> </span><span class="n">T4</span>
<span class="n">PyTorch</span><span class="w"> </span><span class="n">GPU</span><span class="w"> </span><span class="nl">記憶體</span><span class="p">:</span><span class="w"> </span><span class="mf">14.75</span><span class="w"> </span><span class="n">GB</span>

<span class="o">============================================================</span>
<span class="n">系統資源</span>
<span class="o">============================================================</span>
<span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="n">memory</span><span class="p">.</span><span class="n">total</span><span class="w"> </span><span class="o">[</span><span class="n">MiB</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">memory</span><span class="p">.</span><span class="k">free</span><span class="w"> </span><span class="o">[</span><span class="n">MiB</span><span class="o">]</span>
<span class="n">Tesla</span><span class="w"> </span><span class="n">T4</span><span class="p">,</span><span class="w"> </span><span class="mi">15102</span><span class="w"> </span><span class="n">MiB</span><span class="p">,</span><span class="w"> </span><span class="mi">15099</span><span class="w"> </span><span class="n">MiB</span>
</code></pre></div>

<h3>步驟 3：掛載 Google Drive（選用但推薦）</h3>
<p>將模型和結果儲存到 Google Drive，避免 Colab 斷線後遺失：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># ============================================</span>
<span class="c1"># 儲存格 1: 掛載 Google Drive</span>
<span class="c1"># ============================================</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">google.colab</span><span class="w"> </span><span class="kn">import</span> <span class="n">drive</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>

<span class="c1"># 掛載 Drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>

<span class="c1"># 建立專案資料夾</span>
<span class="n">project_folder</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/CNN_Tutorial&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">project_folder</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;✓ Google Drive 已掛載&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;✓ 專案資料夾: </span><span class="si">{</span><span class="n">project_folder</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 切換工作目錄</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="n">project_folder</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;✓ 當前工作目錄: </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<h3>Colab 快捷鍵與技巧</h3>
<p><strong>常用快捷鍵</strong>：</p>
<table>
<thead>
<tr>
<th>功能</th>
<th>快捷鍵</th>
</tr>
</thead>
<tbody>
<tr>
<td>執行當前儲存格</td>
<td><code>Ctrl + Enter</code> (Windows) / <code>Cmd + Enter</code> (Mac)</td>
</tr>
<tr>
<td>執行並移到下一格</td>
<td><code>Shift + Enter</code></td>
</tr>
<tr>
<td>新增程式碼儲存格</td>
<td><code>Ctrl + M B</code> (下方) / <code>Ctrl + M A</code> (上方)</td>
</tr>
<tr>
<td>刪除儲存格</td>
<td><code>Ctrl + M D</code></td>
</tr>
<tr>
<td>註解/取消註解</td>
<td><code>Ctrl + /</code></td>
</tr>
<tr>
<td>顯示快捷鍵列表</td>
<td><code>Ctrl + M H</code></td>
</tr>
</tbody>
</table>
<hr />
<p>(繼續補充 Part 2-5 完整程式碼...)</p>
<h2>第二部分：MNIST + LeNet-5 (Keras)</h2>
<p>本部分將實作經典的 <strong>LeNet-5</strong> 架構，這是 1998 年 Yann LeCun 等人發表的開創性 CNN 模型。</p>
<h3>LeNet-5 架構圖解</h3>
<div class="mermaid">
graph LR
    Input[輸入影像&lt;br/&gt;32×32×1] --&gt; C1[C1: 卷積層&lt;br/&gt;6 filters, 5×5&lt;br/&gt;→ 28×28×6]
    C1 --&gt; S2[S2: 平均池化&lt;br/&gt;2×2, stride=2&lt;br/&gt;→ 14×14×6]
    S2 --&gt; C3[C3: 卷積層&lt;br/&gt;16 filters, 5×5&lt;br/&gt;→ 10×10×16]
    C3 --&gt; S4[S4: 平均池化&lt;br/&gt;2×2, stride=2&lt;br/&gt;→ 5×5×16]
    S4 --&gt; F[Flatten&lt;br/&gt;→ 400]
    F --&gt; C5[C5: 全連接&lt;br/&gt;→ 120]
    C5 --&gt; F6[F6: 全連接&lt;br/&gt;→ 84]
    F6 --&gt; Output[輸出層&lt;br/&gt;→ 10 classes]

    style Input fill:#90EE90
    style C1 fill:#FFE4B5
    style C3 fill:#FFE4B5
    style S2 fill:#87CEEB
    style S4 fill:#87CEEB
    style Output fill:#FFD700
</div>
<h3>完整 Colab Notebook 程式碼</h3>
<p>以下程式碼可直接複製到 Colab 執行：</p>
<div class="codehilite"><pre><span></span><code><span class="c1"># ============================================</span>
<span class="c1"># MNIST + LeNet-5 完整實作（Keras/TensorFlow）</span>
<span class="c1"># 執行環境：Google Colab</span>
<span class="c1"># 預期訓練時間：2-3 分鐘（GPU）</span>
<span class="c1"># 預期準確率：&gt;98.5%</span>
<span class="c1"># ============================================</span>

<span class="c1"># ========== 儲存格 1: 導入套件 ==========</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">AveragePooling2D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.optimizers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.callbacks</span><span class="w"> </span><span class="kn">import</span> <span class="n">EarlyStopping</span><span class="p">,</span> <span class="n">ReduceLROnPlateau</span><span class="p">,</span> <span class="n">ModelCheckpoint</span>

<span class="c1"># 檢查 TensorFlow 版本和 GPU</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TensorFlow 版本: </span><span class="si">{</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;GPU 可用: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">list_physical_devices</span><span class="p">(</span><span class="s1">&#39;GPU&#39;</span><span class="p">))</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 設定隨機種子（可重現結果）</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># ========== 儲存格 2: 載入並視覺化資料 ==========</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;載入 MNIST 資料集...&quot;</span><span class="p">)</span>
<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;訓練集形狀: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>  <span class="c1"># (60000, 28, 28)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;測試集形狀: </span><span class="si">{</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>    <span class="c1"># (10000, 28, 28)</span>

<span class="c1"># 視覺化前 25 張影像</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Label: </span><span class="si">{</span><span class="n">y_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;MNIST 訓練集範例&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># ========== 儲存格 3: 資料預處理 ==========</span>
<span class="k">def</span><span class="w"> </span><span class="nf">preprocess_data</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    預處理 MNIST 資料</span>
<span class="sd">    1. Padding: 28x28 → 32x32 (LeNet-5 原始設計)</span>
<span class="sd">    2. 增加通道維度: (32, 32) → (32, 32, 1)</span>
<span class="sd">    3. 正規化: [0, 255] → [0, 1]</span>
<span class="sd">    4. One-Hot 編碼標籤</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 1. Padding</span>
    <span class="n">X_train_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">X_test_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># 2. Reshape: 增加通道維度</span>
    <span class="n">X_train_pad</span> <span class="o">=</span> <span class="n">X_train_pad</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">X_test_pad</span> <span class="o">=</span> <span class="n">X_test_pad</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># 3. 正規化</span>
    <span class="n">X_train_pad</span> <span class="o">=</span> <span class="n">X_train_pad</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>
    <span class="n">X_test_pad</span> <span class="o">=</span> <span class="n">X_test_pad</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="mf">255.0</span>

    <span class="c1"># 4. One-Hot 編碼</span>
    <span class="n">y_train_cat</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">y_test_cat</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;資料預處理完成！&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  訓練集形狀: </span><span class="si">{</span><span class="n">X_train_pad</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  標籤形狀: </span><span class="si">{</span><span class="n">y_train_cat</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  像素值範圍: [</span><span class="si">{</span><span class="n">X_train_pad</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">X_train_pad</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">X_train_pad</span><span class="p">,</span> <span class="n">y_train_cat</span><span class="p">,</span> <span class="n">X_test_pad</span><span class="p">,</span> <span class="n">y_test_cat</span>

<span class="n">X_train_proc</span><span class="p">,</span> <span class="n">y_train_proc</span><span class="p">,</span> <span class="n">X_test_proc</span><span class="p">,</span> <span class="n">y_test_proc</span> <span class="o">=</span> <span class="n">preprocess_data</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span>
<span class="p">)</span>

<span class="c1"># ========== 儲存格 4: 建立 LeNet-5 模型 ==========</span>
<span class="k">def</span><span class="w"> </span><span class="nf">create_lenet5</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    LeNet-5 架構</span>
<span class="sd">    - 論文: LeCun et al. (1998)</span>
<span class="sd">    - 架構: C1 → S2 → C3 → S4 → Flatten → FC1 → FC2 → Output</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;LeNet-5&#39;</span><span class="p">)</span>

    <span class="c1"># 卷積層 C1: 32x32x1 → 28x28x6</span>
    <span class="c1"># 註：原始 LeNet-5 使用 tanh（1998 年標準），現代 CNN 主流使用 ReLU（收斂更快、避免梯度消失）</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">))</span>

    <span class="c1"># 池化層 S2: 28x28x6 → 14x14x6</span>
    <span class="c1"># 註：原始 LeNet-5 使用 AveragePooling，現代 CNN 主流使用 MaxPooling（保留最顯著特徵）</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">AveragePooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;S2&#39;</span><span class="p">))</span>

    <span class="c1"># 卷積層 C3: 14x14x6 → 10x10x16</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;C3&#39;</span><span class="p">))</span>

    <span class="c1"># 池化層 S4: 10x10x16 → 5x5x16</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">AveragePooling2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;S4&#39;</span><span class="p">))</span>

    <span class="c1"># 展平: 5x5x16 → 400</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;Flatten&#39;</span><span class="p">))</span>

    <span class="c1"># 全連接層 C5: 400 → 120</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;C5&#39;</span><span class="p">))</span>

    <span class="c1"># 全連接層 F6: 120 → 84</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;F6&#39;</span><span class="p">))</span>

    <span class="c1"># 輸出層: 84 → 10</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Output&#39;</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># 建立模型</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">create_lenet5</span><span class="p">()</span>

<span class="c1"># 顯示模型架構</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>

<span class="c1"># ========== 儲存格 5: 編譯模型 ==========</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span>
    <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;✓ 模型編譯完成&quot;</span><span class="p">)</span>

<span class="c1"># ========== 儲存格 6: 設定 Callbacks ==========</span>
<span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># Early Stopping: 驗證損失 5 個 epoch 沒改善就停止</span>
    <span class="n">EarlyStopping</span><span class="p">(</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
        <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">),</span>

    <span class="c1"># 學習率衰減: 驗證損失 3 個 epoch 沒改善就降低學習率</span>
    <span class="n">ReduceLROnPlateau</span><span class="p">(</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
        <span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">min_lr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">),</span>

    <span class="c1"># 儲存最佳模型</span>
    <span class="n">ModelCheckpoint</span><span class="p">(</span>
        <span class="s1">&#39;best_lenet5.h5&#39;</span><span class="p">,</span>
        <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">,</span>
        <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>
<span class="p">]</span>

<span class="c1"># ========== 儲存格 7: 訓練模型 ==========</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;開始訓練...&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train_proc</span><span class="p">,</span> <span class="n">y_train_proc</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="c1"># 10% 作為驗證集</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ 訓練完成！&quot;</span><span class="p">)</span>

<span class="c1"># ========== 儲存格 8: 評估模型 ==========</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;在測試集上評估模型&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">60</span><span class="p">)</span>

<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test_proc</span><span class="p">,</span> <span class="n">y_test_proc</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;測試集損失: </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;測試集準確率: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="c1"># ========== 儲存格 9: 視覺化訓練歷史 ==========</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># 準確率</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;訓練準確率&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">],</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;驗證準確率&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;LeNet-5 訓練準確率&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;準確率&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># 損失</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;訓練損失&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">],</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;驗證損失&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;LeNet-5 訓練損失&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;損失值&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># ========== 儲存格 10: 混淆矩陣 ==========</span>
<span class="c1"># 預測</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_proc</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y_pred_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y_true_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test_proc</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># 計算混淆矩陣</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true_classes</span><span class="p">,</span> <span class="n">y_pred_classes</span><span class="p">)</span>

<span class="c1"># 繪製</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">,</span>
            <span class="n">xticklabels</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="n">yticklabels</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;LeNet-5 混淆矩陣&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;預測標籤&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;真實標籤&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 分類報告</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">分類報告:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true_classes</span><span class="p">,</span> <span class="n">y_pred_classes</span><span class="p">,</span>
                           <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;數字 </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]))</span>

<span class="c1"># ========== 儲存格 11: 預測範例視覺化 ==========</span>
<span class="c1"># 隨機選擇 20 張測試影像</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="mi">20</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flat</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="c1"># 原始影像（28x28，移除 padding）</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="c1"># 預測</span>
    <span class="n">img_proc</span> <span class="o">=</span> <span class="n">X_test_proc</span><span class="p">[</span><span class="n">idx</span><span class="p">:</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">img_proc</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">pred_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
    <span class="n">true_class</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
    <span class="n">confidence</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">pred_class</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>

    <span class="c1"># 顯示</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;green&#39;</span> <span class="k">if</span> <span class="n">pred_class</span> <span class="o">==</span> <span class="n">true_class</span> <span class="k">else</span> <span class="s1">&#39;red&#39;</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
        <span class="sa">f</span><span class="s1">&#39;真實: </span><span class="si">{</span><span class="n">true_class</span><span class="si">}</span><span class="s1"> | 預測: </span><span class="si">{</span><span class="n">pred_class</span><span class="si">}</span><span class="se">\n</span><span class="s1">信心度: </span><span class="si">{</span><span class="n">confidence</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;LeNet-5 預測結果（綠色=正確，紅色=錯誤）&#39;</span><span class="p">,</span>
             <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ 所有程式碼執行完成！&quot;</span><span class="p">)</span>
</code></pre></div>

<h3>程式碼詳細解析</h3>
<h4>1. 資料預處理的 Padding</h4>
<div class="codehilite"><pre><span></span><code><span class="n">X_train_pad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;constant&#39;</span><span class="p">,</span> <span class="n">constant_values</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div>

<p><strong>為什麼需要 Padding？</strong><br />
- LeNet-5 原始論文設計為 32×32 輸入<br />
- MNIST 影像是 28×28<br />
- 填充 2 像素黑邊：28 + 2×2 = 32</p>
<p><strong>參數說明</strong>：<br />
- <code>((0,0), (2,2), (2,2))</code>：<br />
  - 第一維（樣本數）：不填充<br />
  - 第二維（高度）：上下各填充 2<br />
  - 第三維（寬度）：左右各填充 2<br />
- <code>mode='constant', constant_values=0</code>：填充黑色（0）</p>
<h4>2. One-Hot 編碼</h4>
<div class="codehilite"><pre><span></span><code><span class="n">y_train_cat</span> <span class="o">=</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div>

<p><strong>轉換示例</strong>：</p>
<div class="codehilite"><pre><span></span><code><span class="n">原始標籤</span><span class="p">:</span> <span class="mi">5</span>
<span class="n">One</span><span class="o">-</span><span class="n">Hot</span><span class="p">:</span>  <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
          <span class="err">└─────────────┬─────────────┘</span>
                      <span class="n">索引</span> <span class="mi">5</span> <span class="n">為</span> <span class="mi">1</span>
</code></pre></div>

<p><strong>為什麼需要 One-Hot？</strong><br />
- Softmax 輸出層需要向量形式<br />
- 交叉熵損失函數的要求<br />
- 避免類別之間的順序關係（如 9 &gt; 1）</p>
<h4>3. Callbacks 詳解</h4>
<table>
<thead>
<tr>
<th>Callback</th>
<th>功能</th>
<th>參數說明</th>
<th>效果</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>EarlyStopping</strong></td>
<td>提前停止</td>
<td><code>patience=5</code></td>
<td>5 個 epoch 沒進步就停止</td>
</tr>
<tr>
<td><strong>ReduceLROnPlateau</strong></td>
<td>學習率衰減</td>
<td><code>factor=0.5, patience=3</code></td>
<td>3 個 epoch 沒進步，學習率減半</td>
</tr>
<tr>
<td><strong>ModelCheckpoint</strong></td>
<td>儲存模型</td>
<td><code>save_best_only=True</code></td>
<td>只保存最佳模型</td>
</tr>
</tbody>
</table>
<p><strong>學習率衰減示例</strong>：</p>
<div class="codehilite"><pre><span></span><code>Epoch 1-5:  lr = 0.001 (初始)
Epoch 6-8:  lr = 0.001 (驗證損失持續改善)
Epoch 9-11: lr = 0.001 (驗證損失停滯)
Epoch 12:   lr = 0.0005 (觸發衰減)
Epoch 15:   lr = 0.00025 (再次衰減)
</code></pre></div>

<h4>4. LeNet-5 vs 現代 CNN</h4>
<table>
<thead>
<tr>
<th>特性</th>
<th>LeNet-5 (1998)</th>
<th>現代 CNN (2020+)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>激活函數</strong></td>
<td>tanh</td>
<td>ReLU / GELU</td>
</tr>
<tr>
<td><strong>池化方式</strong></td>
<td>Average Pooling</td>
<td>Max Pooling</td>
</tr>
<tr>
<td><strong>正規化</strong></td>
<td>無</td>
<td>Batch Normalization</td>
</tr>
<tr>
<td><strong>防過擬合</strong></td>
<td>無</td>
<td>Dropout, L2 regularization</td>
</tr>
<tr>
<td><strong>優化器</strong></td>
<td>SGD</td>
<td>Adam, AdamW</td>
</tr>
<tr>
<td><strong>參數量</strong></td>
<td>~60K</td>
<td>數百萬到數十億</td>
</tr>
</tbody>
</table>
<h3>預期結果</h3>
<p><strong>訓練過程</strong>（GPU，約 2-3 分鐘）：</p>
<div class="codehilite"><pre><span></span><code>Epoch 1/20
422/422 [==============================] - 3s 6ms/step - loss: 0.3421 - accuracy: 0.8945 - val_loss: 0.1234 - val_accuracy: 0.9632
Epoch 2/20
422/422 [==============================] - 2s 5ms/step - loss: 0.0981 - accuracy: 0.9701 - val_loss: 0.0789 - val_accuracy: 0.9758
...
Epoch 10/20
422/422 [==============================] - 2s 5ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.0412 - val_accuracy: 0.9875

Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
</code></pre></div>

<p><strong>最終測試結果</strong>：</p>
<div class="codehilite"><pre><span></span><code>============================================================
在測試集上評估模型
============================================================
測試集損失: 0.0389
測試集準確率: 98.76%
</code></pre></div>

<p><strong>分類報告範例</strong>：</p>
<div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

      數字 0       0.99      0.99      0.99       980
      數字 1       0.99      1.00      0.99      1135
      數字 2       0.99      0.98      0.98      1032
      數字 3       0.98      0.99      0.99      1010
      數字 4       0.99      0.98      0.99       982
      數字 5       0.98      0.99      0.98       892
      數字 6       0.99      0.99      0.99       958
      數字 7       0.98      0.99      0.99      1028
      數字 8       0.99      0.98      0.98       974
      數字 9       0.98      0.98      0.98      1009

    accuracy                           0.99     10000
</code></pre></div>

<h3>常見問題排解</h3>
<p><strong>Q1: 為什麼準確率卡在 95% 不上升？</strong></p>
<p>可能原因與解決方法：<br />
- ❌ 學習率過大 → 降低至 0.001 或 0.0001<br />
- ❌ 資料未正規化 → 確認除以 255<br />
- ❌ Padding 錯誤 → 確認形狀為 (60000, 32, 32, 1)<br />
- ❌ 標籤未 One-Hot → 檢查 y_train_proc.shape</p>
<p><strong>Q2: 為什麼訓練很慢？</strong></p>
<p>檢查清單：<br />
- ✅ GPU 已啟用（最重要！）<br />
- ✅ batch_size 設為 128-256<br />
- ✅ 使用 <code>model.fit()</code> 而非手寫迴圈</p>
<p><strong>速度對比</strong>：</p>
<div class="codehilite"><pre><span></span><code>CPU (batch_size=128):  約 10-15 分鐘
GPU (batch_size=128):  約 2-3 分鐘  ← 快 5 倍
GPU (batch_size=256):  約 1-2 分鐘  ← 快 8 倍
</code></pre></div>

<p><strong>Q3: 出現記憶體不足錯誤？</strong></p>
<div class="codehilite"><pre><span></span><code><span class="c1"># 減少 batch_size</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>  <span class="c1"># 從 128 減到 64</span>

<span class="c1"># 或清空 GPU 記憶體</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="n">K</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>
</code></pre></div>

<hr />
<h2>第二部分總結</h2>
<p>恭喜你完成 Part 1！你已經學會了：</p>
<p>✅ <strong>基礎知識</strong>：<br />
- 認識 MNIST 和 CIFAR-10 資料集<br />
- 理解 Keras 和 PyTorch 的差異<br />
- 熟悉 CNN 的專有名詞</p>
<p>✅ <strong>實作能力</strong>：<br />
- 在 Google Colab 設置 GPU 環境<br />
- 使用 Keras 實作 LeNet-5<br />
- MNIST 準確率達到 98%+</p>
<p>✅ <strong>關鍵技術</strong>：<br />
- 資料預處理與正規化<br />
- One-Hot 編碼<br />
- 使用 Callbacks (EarlyStopping, ReduceLROnPlateau)<br />
- 模型評估與視覺化</p>
<h3>下一步：深入 PyTorch</h3>
<p>現在你已經掌握了 Keras 的高階 API，準備好深入理解深度學習的底層運作了嗎？</p>
<p><strong>請繼續閱讀</strong>：<code>CNN_intro_b07_part2.md</code> - PyTorch 深度實戰</p>
<p>在 Part 2 中，你將學習：<br />
- PyTorch 的核心概念（Tensor, nn.Module, DataLoader）<br />
- 手寫完整訓練迴圈<br />
- SimpleCNN 現代化架構<br />
- 達到 99%+ 的準確率</p>
<hr />
<p><strong>本文件完成時間</strong>：2025-10-07 12:00:00<br />
<strong>版本</strong>：b07<br />
<strong>下一部分</strong>：<code>CNN_intro_b07_part2.md</code> (PyTorch 深度實戰)</p></div>
    
    <!-- Highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
    
    <!-- Mermaid -->
    <script type="module">
        import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
        mermaid.initialize({
            "startOnLoad": true,
            "theme": "dark",
            "securityLevel": "loose"
});
    </script>
</body>
</html>